<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://sabertoaster.github.io/vi/feed.xml" rel="self" type="application/atom+xml"/><link href="https://sabertoaster.github.io/vi/" rel="alternate" type="text/html" hreflang="en"/><updated>2026-01-02T10:35:11+00:00</updated><id>https://sabertoaster.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry xml:lang="en"><title type="html">How to start Computational Neuroscience</title><link href="https://sabertoaster.github.io/vi/blog/2025/incf-open-neuroscience/" rel="alternate" type="text/html" title="How to start Computational Neuroscience"/><published>2025-08-01T12:00:00+00:00</published><updated>2025-08-01T12:00:00+00:00</updated><id>https://sabertoaster.github.io/blog/2025/incf-open-neuroscience</id><content type="html" xml:base="https://sabertoaster.github.io/blog/2025/incf-open-neuroscience/"><![CDATA[<p>Disclaimer: I didn’t own any of the contents and it all belongs to the rightful owner credited/ mentioned/ referenced at the end of the post.</p> <blockquote> <p>Purpose of the study track is to provide a convenient and guided starting point to acquire the knowledge and skills required for open neuroscience.</p> </blockquote> <hr/> <h2 id="brief-introduction">Brief introduction</h2> <details><summary>Research in the neurosciences is becoming ever more demanding of a variety of sophisticated technical skills and computational competence, especially when one factors in the objective of making this science reproducible, open, and FAIR.</summary> <blockquote> <p>In collaboration with the INCF, the Canadian Open Neuroscience Platform (CONP) is assembling a curated set of international content that aims to provide guidance through the increasingly complex landscape of skills and tools required for open neuroscience research. Such initiatives are key to facilitating the acquisition of the skills and knowledge comprising open-science workflows (from ‘open-by-design’ experimental conception, through reproducible analysis, to safe data sharing). This is a living collection, with many materials to be added and updated still. <br/> The CONP is funded by a Brain Canada Platform Support Grant Competition Award, as well as funds and in-kind support from sponsor organizations. Please visit the <a href="https://conp.ca/">CONP</a> and <a href="https://braincanada.ca/">Brain Canada</a> websites linked below for more information.</p> </blockquote> </details> <p>The track is divided into 3 seperate parts:</p> <ul> <li><a href="https://training.incf.org/collection/data-science-tools-trade">Data Science - Tools of the Trade</a>: <br/> This collection looks to introduce neuroscience trainees to many of the basic tools and techniques essential for most computationally intensive neuroscience research environments.</li> <li><a href="https://training.incf.org/collection/statistics-machine-learning">Techniques on Statistics and Machine Learning</a>: <br/> These courses will introduce the basics of powerful machine learning techniques and the elements of traditional statistical approaches provide foundational knowledge for multivariate analyses.</li> <li><a href="https://training.incf.org/collection/standards-best-practices">Standard &amp; Best Practices</a>: <br/> This collection of courses and lessons intends to provide resources for standards and best practices in Open Science, Publishing, Ethics, and more.</li> </ul> <hr/> <h2 id="data-science---tools-of-the-trade"><a href="https://training.incf.org/collection/data-science-tools-trade">Data Science - Tools of the Trade</a></h2> <details><summary>Table of contents</summary> <ol> <li><a href="https://training.incf.org/course/conceptual-background-refreshers">Conceptual background &amp; refreshers</a> <ul> <li>Review of modelling</li> <li>Flash math refresher</li> <li>Models of neural function</li> <li>Overview of brain-imaging techniques</li> </ul> </li> <li><a href="https://training.incf.org/course/programming">Programming essentials</a> <ul> <li>Basics required for navigating command-line environments</li> <li>Python</li> <li>R</li> <li>Matlab/Octave</li> </ul> </li> <li><a href="https://training.incf.org/course/notebooks">Notebooks</a> <ul> <li>For teaching and learning</li> <li>As part of an everyday, scientific workflow</li> <li>As a complement to standard PDF publications</li> </ul> </li> <li><a href="https://training.incf.org/course/versioning-containerization">Versioning and containerization</a> <ul> <li>Overview</li> <li>Reproducibility</li> <li>Local execution</li> </ul> </li> <li><a href="https://training.incf.org/course/data-management-repositories-search-engines">Data Management, Repositories &amp; Search Engines</a> <ul> <li>The importance and utility of Research Data Management</li> <li>Sources and reuse of neuroscience data</li> </ul> </li> <li><a href="https://training.incf.org/course/data-management-repositories-search-engines">High-performance computing</a> <ul> <li>Case studies</li> <li>CLI environments (tools, scheduling, etc.)</li> <li>GUI environments</li> </ul> </li> </ol> </details> <h3 id="conceptual-background--refreshers">Conceptual background &amp; refreshers</h3> <hr/> <h2 id="statistics-and-machine-learning"><a href="https://training.incf.org/collection/statistics-machine-learning">Statistics and Machine Learning</a></h2> <details><summary>Table of contents</summary> <ol> <li><a href="https://training.incf.org/course/glm-regression-models-and-latent-variables">GLM, regression models, and latent variables</a> <ul> <li>Refresher for regressions models and GLM</li> <li>Addition of different noise distributions and advanced models</li> <li>Logistic regression</li> <li>Latent variables</li> </ul> </li> <li><a href="https://training.incf.org/course/machine-learning-conp">Machine learning</a> <ul> <li>Conceptual overview</li> <li>Hands-on application of simple machine learning to neuroscience data</li> <li>Advanced models</li> <li>Deep learning</li> <li>Caveats in deep learning applications to neuroscience</li> </ul> </li> <li><a href="https://training.incf.org/course/statistical-software">Statistical software</a> <ul> <li>scikit-learn</li> <li>nilearn</li> <li>JASP</li> </ul> </li> </ol> </details> <hr/> <h2 id="standard--best-practices"><a href="https://training.incf.org/collection/standards-best-practices">Standard &amp; Best Practices</a></h2> <details><summary>Table of contents</summary> <ol> <li><a href="https://training.incf.org/course/open-science-practices-and-policies">Open Science: Practices and Policies</a> <ul> <li>The Open Science Training Handbook</li> <li>Standards for Project Management and Organization</li> <li>Support Your Research With Data Management Planning!</li> </ul> </li> <li><a href="https://training.incf.org/course/ethics-and-governance">Ethics and Governance</a></li> <li><a href="https://training.incf.org/course/publishing">Publishing</a> (Still under development)</li> </ol> </details> <p>A few more things:</p> <ul> <li>From <a href="https://docs.neuromatch.io/p/CpPZ_P0Tl9vv6s/2025-Academy-Professional-Development">Neuromatch Academy 2025</a>: How to Build Data Pipelines for Neuroscience &amp; AI: https://youtu.be/PpDZgFyUlMQ</li> </ul> <hr/> <h2 id="references">References</h2> <p><a href="https://training.incf.org/studytrack/open-neuroscience-starter-kit">INCF Open Neuroscience Starter Kit</a></p>]]></content><author><name></name></author><category term="comp-neursci"/><summary type="html"><![CDATA[Notes and commentaries]]></summary></entry><entry xml:lang="en"><title type="html">Mathematics for Computational Neuroscience</title><link href="https://sabertoaster.github.io/vi/blog/2025/math-for-neuro/" rel="alternate" type="text/html" title="Mathematics for Computational Neuroscience"/><published>2025-08-01T12:00:00+00:00</published><updated>2025-08-01T12:00:00+00:00</updated><id>https://sabertoaster.github.io/blog/2025/math-for-neuro</id><content type="html" xml:base="https://sabertoaster.github.io/blog/2025/math-for-neuro/"><![CDATA[<p>Hosted by Speaker: <a href="https://training.incf.org/taxonomy/term/160">Alex Williams</a></p> <h2 id="1-membrane-potential-introduction">1. <a href="https://training.incf.org/lesson/membrane-potential-introduction">Membrane Potential Introduction</a></h2> <details><summary>This lesson introduces the membrane potential equation</summary> <h4 id="what-is-membrane-potential">What is Membrane Potential?</h4> <p>The membrane potential ($V_m$) is the voltage difference across a neuron’s membrane, defined as $V_m = V_i - V_e$, where $V_i$ is the intracellular potential and $V_e$ is the extracellular potential.</p> <ul> <li>It’s measured in millivolts (mV), with the inside of the cell typically being negative relative to the outside (e.g., ~-70 mV at rest).</li> <li>This potential arises from the asymmetric distribution of ions like Sodium (Na+), Potassium (K+), and Chloride (Cl-) across the membrane, a state maintained by active ion pumps.</li> </ul> <h4 id="electrical-properties-of-the-membrane">Electrical Properties of the Membrane</h4> <p>To model the cell membrane, we can abstract its physical properties into an equivalent electrical circuit:</p> <ol> <li><strong>Capacitor (<code class="language-plaintext highlighter-rouge">insulator</code>)</strong>: The lipid bilayer separates charges, acting like a capacitor that can store charge. This is crucial for generating action potentials.</li> <li><strong>Resistors (<code class="language-plaintext highlighter-rouge">conductors</code>)</strong>: Ion channels allow ions to move across the membrane, functioning as resistors.</li> <li><strong>Voltage Source (Battery)</strong>: The concentration gradients of ions create an electrochemical potential, which acts as a battery.</li> </ol> <p>This leads to the simplest model of a cell membrane patch as an RC circuit:</p> <pre><code class="language-mermaid">---
title: Simplest Cellular Membrane Circuit
---
graph TD
    subgraph "Inside (V_i)"
        A --- C
    end
    subgraph "Outside (V_e)"
        B --- D
    end

    subgraph "Membrane"
        C -- C_m --&gt; D
        C -- R_m --&gt; E
        E -- E_L --&gt; D
    end

    A -- V_m --- B

    linkStyle 3 stroke-width:0px,fill:none;
</code></pre> <h4 id="governing-equations">Governing Equations</h4> <ul> <li><strong><a href="https://www.physiologyweb.com/calculators/nernst_potential_calculator.html">Nernst equation</a></strong>: Calculates the equilibrium potential for a single ion species.</li> <li><strong>Goldman equation</strong>: An extension of the Nernst equation for multiple ion species, used to calculate the resting membrane potential.</li> </ul> </details> <hr/> <h2 id="2-the-membrane-equation-passive-neuron">2. The Membrane Equation (Passive Neuron)</h2> <h2 id="3-separation-of-variables-solving-passive-membrane">3. Separation of Variables (Solving Passive Membrane)</h2> <p>Solving the passive membrane equation</p> <h2 id="4-injecting-current-into-a-passive-membrane">4. Injecting Current Into a Passive Membrane</h2> <p>Injecting current into a passive membrane</p> <h2 id="5-response-to-a-current-step">5. Response to a Current Step</h2> <p>Response to injected current</p> <h2 id="6-numerically-solving-the-membrane-equation">6. Numerically Solving the Membrane Equation</h2> <p>Explains the logic behind dealing with more complex currents by solving the membrane equation numerically.</p> <h2 id="7-intro-to-conductance-based-models">7. Intro to Conductance-Based Models</h2> <p>Introducing voltage-dependent ion channels into the passive membrane</p> <h2 id="8-hodgkin-huxley-channel-models">8. Hodgkin Huxley Channel Models</h2> <p>Introducing Hodgkin &amp; Huxley’s voltage dependent ion channel models, with emphasis on the sodium conductance</p> <h2 id="9-hodgkin-huxley-squid-axon-model">9. Hodgkin-Huxley Squid Axon Model</h2> <p>Introducing the classical Hodgkin &amp; Huxley squid axon model with sodium and potassium conductances</p> <h2 id="10-multi-compartment-conductance-based-models">10. Multi-Compartment Conductance-Based Models</h2> <p>This lesson extends the conductance-based model equation to multiple neuronal compartments, taking more complex morphology into account.</p> <h3 id="references">References</h3> <p><a href="https://training.incf.org/course/basic-mathematics-computational-neuroscience">INCF Basic Mathematics for Computational Neuroscience</a></p>]]></content><author><name></name></author><category term="comp-neursci"/><category term="math"/><summary type="html"><![CDATA[Notes and commentaries]]></summary></entry><entry xml:lang="en"><title type="html">Learning Resources</title><link href="https://sabertoaster.github.io/vi/blog/2025/awesome-learning-path/" rel="alternate" type="text/html" title="Learning Resources"/><published>2025-07-01T12:00:00+00:00</published><updated>2025-07-01T12:00:00+00:00</updated><id>https://sabertoaster.github.io/blog/2025/awesome-learning-path</id><content type="html" xml:base="https://sabertoaster.github.io/blog/2025/awesome-learning-path/"><![CDATA[<blockquote> <p><em>An attempt of an undergrad to create a curated repository of computational neuroscience and brain-inspired artificial intelligence resources, which can also including Data Science, pure Math, Machine Learning, Deep Learning, and not constrictively limiting beyond those topics. Leave a star if you believe I can make it, or follow me if you don’t.</em></p> </blockquote> <div style="float: right"> SaberToaster, 2025 </div> <p><br/></p> <h2 id="learning-resources">Learning Resources</h2> <details><summary>MOOCs &amp; Online Courses</summary> <table> <thead> <tr> <th>Course</th> <th>Provider/Author</th> <th>Focus</th> <th>Best For</th> <th>Access</th> </tr> </thead> <tbody> <tr> <td><strong>Computational Neuroscience</strong></td> <td>Coursera</td> <td>Mathematical foundations of neural computation</td> <td>CS students transitioning to neuro</td> <td><a href="https://www.coursera.org/learn/computational-neuroscience">Course</a></td> </tr> <tr> <td><strong>Neuroscience for Machine Learners</strong></td> <td>Neuromatch Academy</td> <td>CS-friendly intro to neuroscience</td> <td>ML practitioners</td> <td><a href="https://neuro4ml.github.io/">Course</a> • <a href="https://youtube.com/playlist?list=PL09WqqDbQWHErc8xOyWdKpNEk78Jjk0EL">Videos</a></td> </tr> <tr> <td><strong>Machine Learning Specialization</strong></td> <td>Coursera</td> <td>Standard ML foundations</td> <td>Beginners</td> <td><a href="https://www.coursera.org/specializations/machine-learning-introduction">Course</a></td> </tr> <tr> <td><strong>Deep Learning Specialization</strong></td> <td>Coursera</td> <td>Neural networks and architectures</td> <td>Intermediate practitioners</td> <td><a href="https://www.coursera.org/specializations/deep-learning">Course</a></td> </tr> <tr> <td><strong>Predictive Brain Lab Resources</strong></td> <td>MIT</td> <td>Heavy NeuroAI focus</td> <td>Advanced researchers</td> <td><a href="https://predictive-brain-lab.github.io/Lab-Wiki/documents/neuro-ai/neuroai-resources.html">Resources</a></td> </tr> <tr> <td><strong>Computational Neuroscience 2020</strong></td> <td>Michelle R. Greene, Ph.D</td> <td>Self-paced neuroscience curriculum</td> <td>Self-directed learners</td> <td><a href="https://mrgreene09.github.io/compNeuro2020/">Course</a></td> </tr> </tbody> </table> </details> <details><summary>Essential Books &amp; Textbooks</summary> <h5 id="mathematical-foundations">Mathematical Foundations</h5> <table> <thead> <tr> <th>Title</th> <th>Authors</th> <th>Year</th> <th>Focus</th> <th>Best For</th> <th>Access</th> </tr> </thead> <tbody> <tr> <td><strong>Neuronal Dynamics</strong></td> <td>Wulfram Gerstner et al</td> <td>2014</td> <td>Mathematical models of neural dynamics</td> <td>Physics background</td> <td><a href="https://neuronaldynamics.epfl.ch/">Free Online</a></td> </tr> <tr> <td><strong>Theoretical Neuroscience</strong></td> <td>Dayan &amp; Abbott</td> <td>2001</td> <td>Mathematical framework for computation</td> <td>CS + Physics students</td> <td>Essential textbook</td> </tr> <tr> <td><strong>Dynamical Systems in Neuroscience</strong></td> <td>Izhikevich</td> <td>2007</td> <td>Mathematical models of neuronal behavior</td> <td>Advanced mathematical focus</td> <td>Standard reference</td> </tr> <tr> <td><strong>Neural Engineering</strong></td> <td>Eliasmith &amp; Anderson</td> <td>2003</td> <td>Neural representation principles (NEF)</td> <td>Engineering approach</td> <td>NEF methodology foundation</td> </tr> </tbody> </table> <h5 id="aiml-references">AI/ML References</h5> <table> <thead> <tr> <th>Title</th> <th>Authors</th> <th>Year</th> <th>Focus</th> <th>Notes</th> </tr> </thead> <tbody> <tr> <td><strong>Deep Learning</strong></td> <td>Goodfellow et al.</td> <td>2016</td> <td>Comprehensive DL textbook</td> <td>Standard reference</td> </tr> <tr> <td><strong>Attention Is All You Need</strong></td> <td>Vaswani et al.</td> <td>2017</td> <td>Transformer architecture</td> <td>Revolutionary paper</td> </tr> </tbody> </table> </details> <details><summary>Blogs &amp; Personal Resources</summary> <table> <thead> <tr> <th>Author</th> <th>Affiliation</th> <th>Focus</th> <th>Why Follow</th> <th>URL</th> </tr> </thead> <tbody> <tr> <td><strong>Christopher Olah</strong></td> <td>Anthropic AI co-founder</td> <td>Neural network interpretability</td> <td>Clear explanations of complex concepts</td> <td><a href="https://colah.github.io/">Blog</a></td> </tr> <tr> <td><strong>Aman Chadha</strong></td> <td>AWS GenAI Chief Research Scientist</td> <td>AI research and applications</td> <td>Industry perspective on cutting-edge research</td> <td><a href="https://aman.ai/">Homepage</a></td> </tr> <tr> <td><strong>Charles Frye</strong></td> <td>Helen Wills Neuroscience Institute</td> <td>Computational neuroscience</td> <td>Academic insights bridging theory and practice</td> <td><a href="https://charlesfrye.github.io/about/">Homepage</a> • <a href="https://charlesfrye.github.io/FoundationalNeuroscience/">CNS</a></td> </tr> </tbody> </table> </details> <details><summary>YouTube Channels</summary> <table> <thead> <tr> <th>Channel</th> <th>Creator</th> <th>Focus</th> <th>Why Watch</th> <th>URL</th> </tr> </thead> <tbody> <tr> <td><strong>3Blue1Brown</strong></td> <td>Grant Sanderson</td> <td>Mathematical visualizations</td> <td>Best math/ML concept explanations</td> <td><a href="https://www.youtube.com/@3blue1brown">Channel</a></td> </tr> <tr> <td><strong>Artem Kirsanov</strong></td> <td>Artem Kirsanov</td> <td>Computational neuroscience animations</td> <td>Covers most CNS concepts with clear animations</td> <td><a href="https://www.youtube.com/@ArtemKirsanov">Channel</a></td> </tr> <tr> <td><strong>Deepia</strong></td> <td>Various</td> <td>AI/ML visualizations</td> <td>Cool visualization techniques</td> <td><a href="https://www.youtube.com/@Deepia-ls2fo">Channel</a></td> </tr> <tr> <td><strong>Computerphile</strong></td> <td>University team</td> <td>Computer science concepts</td> <td>CS fundamentals relevant to neurocomputation</td> <td><a href="https://www.youtube.com/@Computerphile">Channel</a></td> </tr> </tbody> </table> </details> <hr/> <h2 id="research-literature">Research Literature</h2> <details><summary>Mathematical &amp; Computational Foundations</summary> <table> <thead> <tr> <th>Paper/Book</th> <th>Authors</th> <th>Year</th> <th>Key Contribution</th> <th>Impact</th> <th>URL</th> </tr> </thead> <tbody> <tr> <td><strong>What the Frog’s Eye Tells the Frog’s Brain</strong></td> <td>Lettvin et al.</td> <td>1959</td> <td>Feature detection in visual system</td> <td>Classic computational neuro</td> <td> </td> </tr> <tr> <td><strong>Computational neuroscience: a frontier</strong></td> <td>Multiple</td> <td>2020</td> <td>State of the field overview</td> <td>Recent comprehensive review</td> <td><a href="https://academic.oup.com/nsr/article/7/9/1418/5856589">PDF</a></td> </tr> </tbody> </table> <p><em>Note: Mathematical foundations table to be expanded with specific papers on neural dynamics, information theory, and computational methods.</em></p> </details> <details><summary>NeuroAI Integration Papers</summary> <table> <thead> <tr> <th>Paper</th> <th>Authors</th> <th>Year</th> <th>Key Contribution</th> <th>Research Area</th> <th>Notes</th> </tr> </thead> <tbody> <tr> <td><strong>The Genomic Bottleneck</strong></td> <td>Zador</td> <td>2019</td> <td>Constraints on innate vs learned computation</td> <td>Evolutionary computation</td> <td>Influential perspective paper</td> </tr> <tr> <td><strong>Brain-Inspired AI</strong></td> <td>Hassabis et al.</td> <td>2017</td> <td>Neuroscience-AI bidirectional influence</td> <td>AI methodology</td> <td>DeepMind perspective</td> </tr> <tr> <td><strong>Surrogate Gradient Learning in SNN</strong></td> <td>Neftci et al.</td> <td>2019</td> <td>Training spiking neural networks</td> <td>SNN algorithms</td> <td>Key training methodology</td> </tr> <tr> <td><strong>Deep Learning with Spiking Neurons</strong></td> <td>Pfeiffer &amp; Pfeil</td> <td>2018</td> <td>Neuromorphic deep learning approaches</td> <td>Hardware-software co-design</td> <td>Practical implementation focus</td> </tr> <tr> <td><strong>Towards Spike-Based Machine Intelligence</strong></td> <td>Roy et al.</td> <td>2019</td> <td>Comprehensive SNN survey</td> <td>SNN overview</td> <td>State-of-the-art review</td> </tr> </tbody> </table> </details> <details><summary>Specialized Topics</summary> <h5 id="spiking-neural-networks">Spiking Neural Networks</h5> <p><em>Papers on temporal dynamics, energy efficiency, and biological realism</em></p> <h5 id="hopfield-networks">Hopfield Networks</h5> <p><em>Classic associative memory models and modern variants</em></p> <h5 id="attention-mechanisms">Attention Mechanisms</h5> <p><em>Biological inspiration and computational implementations</em></p> <p><em>These sections to be populated with specific paper recommendations</em></p> </details> <hr/> <h2 id="academic--research-community">Academic &amp; Research Community</h2> <details><summary>Research Institutions &amp; Labs</summary> <h5 id="north-america">North America</h5> <table> <thead> <tr> <th>Institution</th> <th>Key Researchers</th> <th>Research Focus</th> <th>Location</th> <th>URL</th> </tr> </thead> <tbody> <tr> <td><strong>MIT McGovern Institute</strong></td> <td>Multiple PIs</td> <td>Computational neuroscience</td> <td>Cambridge, MA</td> <td> </td> </tr> <tr> <td><strong>Stanford Wu Tsai</strong></td> <td>Multiple PIs</td> <td>Neural computation and AI</td> <td>Stanford, CA</td> <td> </td> </tr> <tr> <td><strong>Allen Institute</strong></td> <td>Christof Koch</td> <td>Large-scale brain mapping</td> <td>Seattle, WA</td> <td> </td> </tr> <tr> <td><strong>HHMI Janelia</strong></td> <td>Multiple PIs</td> <td>Neural circuits and computation</td> <td>Ashburn, VA</td> <td> </td> </tr> <tr> <td><strong>Cold Spring Harbor Laboratory</strong></td> <td>Multiple PIs</td> <td>NeuroAI internships + postdocs</td> <td>NYC, NY</td> <td><a href="https://www.cshl.edu/research/neuroscience/neuroai/">NeuroAI Program</a></td> </tr> </tbody> </table> <h5 id="europe">Europe</h5> <table> <thead> <tr> <th>Institution</th> <th>Key Researchers</th> <th>Research Focus</th> <th>Location</th> <th>URL</th> </tr> </thead> <tbody> <tr> <td><strong>EPFL (Computational Neuroscience)</strong></td> <td>Wulfram Gerstner</td> <td>Mathematical neuroscience</td> <td>Switzerland</td> <td><a href="https://www.epfl.ch/labs/lcn/">LCN Lab</a></td> </tr> <tr> <td><strong>EPFL (NeuroAI)</strong></td> <td>Martin Schrimpf</td> <td>Brain-AI alignment</td> <td>Switzerland</td> <td><a href="https://www.epfl.ch/labs/schrimpflab/">Schrimpf Lab</a></td> </tr> <tr> <td><strong>ETH Zurich INI</strong></td> <td>Multiple PIs</td> <td>Neuromorphic engineering</td> <td>Switzerland</td> <td> </td> </tr> <tr> <td><strong>DeepMind Neuroscience</strong></td> <td>Multiple researchers</td> <td>Brain-inspired AI</td> <td>London, UK</td> <td> </td> </tr> <tr> <td><strong>IT:U</strong></td> <td>Jie Mei</td> <td>Neuromodulatory mechanisms</td> <td>Austria</td> <td><a href="https://it-u.at/en/research/research-groups/computational-neuroscience/">Computational Neuroscience</a></td> </tr> </tbody> </table> <h5 id="asia">Asia</h5> <table> <thead> <tr> <th>Institution</th> <th>Key Researchers</th> <th>Research Focus</th> <th>Location</th> <th>URL</th> </tr> </thead> <tbody> <tr> <td><strong>KWANGWOON University</strong></td> <td>Young-Seok Choi</td> <td>Neuroengineering and AI</td> <td>Korea</td> <td><a href="https://sites.google.com/view/neuroailab/home">NeuroAI Lab</a></td> </tr> <tr> <td><strong>Shanghai Jiao Tong University</strong></td> <td>Ru-Yuan Zhang</td> <td>Cognitive computational neuroscience</td> <td>Shanghai, China</td> <td><a href="https://ruyuanzhang.github.io/index.html">Zhang Lab</a></td> </tr> </tbody> </table> </details> <details><summary>Journals &amp; Conferences</summary> <h5 id="high-impact-journals">High-Impact Journals</h5> <table> <thead> <tr> <th>Journal</th> <th>Type</th> <th>Focus</th> <th>Impact Factor</th> <th>Submission Focus</th> </tr> </thead> <tbody> <tr> <td><strong>Nature Neuroscience</strong></td> <td>Journal</td> <td>High-impact neuroscience research</td> <td>&gt;20</td> <td>Breakthrough discoveries</td> </tr> <tr> <td><strong>Neuron</strong></td> <td>Journal</td> <td>Cellular and systems neuroscience</td> <td>&gt;15</td> <td>Mechanistic insights</td> </tr> <tr> <td><strong>Neural Computation</strong></td> <td>Journal</td> <td>Computational theory</td> <td>~3</td> <td>Mathematical models</td> </tr> </tbody> </table> <h5 id="open-access-venues">Open-Access Venues</h5> <table> <thead> <tr> <th>Venue</th> <th>Type</th> <th>Focus</th> <th>Impact Factor</th> <th>Why Submit Here</th> </tr> </thead> <tbody> <tr> <td><strong>PLoS Computational Biology</strong></td> <td>Journal</td> <td>Computational biology</td> <td>~4</td> <td>Open access, broad reach</td> </tr> <tr> <td><strong>Frontiers in Computational Neuroscience</strong></td> <td>Journal</td> <td>Computational approaches</td> <td>~3</td> <td>Fast review, open access</td> </tr> </tbody> </table> <h5 id="key-conferences">Key Conferences</h5> <table> <thead> <tr> <th>Conference</th> <th>Full Name</th> <th>Focus</th> <th>Venue Type</th> <th>Notes</th> </tr> </thead> <tbody> <tr> <td><strong>NeurIPS</strong></td> <td>Neural Information Processing Systems</td> <td>ML/AI with neuroscience connections</td> <td>Annual</td> <td>Premier ML conference</td> </tr> <tr> <td><strong>COSYNE</strong></td> <td>Computational and Systems Neuroscience</td> <td>Computational neuroscience</td> <td>Annual</td> <td>Theory-focused</td> </tr> <tr> <td><strong>ICLR</strong></td> <td>International Conference on Learning Representations</td> <td>Representation learning</td> <td>Annual</td> <td>Rising importance in AI</td> </tr> <tr> <td><strong>CNS</strong></td> <td>Cognitive Neuroscience Society</td> <td>Cognitive neuroscience</td> <td>Annual</td> <td>Experimental focus</td> </tr> <tr> <td><strong>ICMNAI</strong></td> <td>International Conference on Mathematics of Neuroscience and AI</td> <td>Mathematics intersection</td> <td>Annual</td> <td><a href="https://www.neuromonster.org/contact">Website</a></td> </tr> </tbody> </table> </details> <hr/> <h2 id="computational-tools--software">Computational Tools &amp; Software</h2> <details><summary>Neural Simulation Platforms</summary> <table> <thead> <tr> <th>Tool</th> <th>Category</th> <th>Description</th> <th>Language</th> <th>Best For</th> <th>URL</th> </tr> </thead> <tbody> <tr> <td><strong>Brian2</strong></td> <td>SNN Simulation</td> <td>Clock-driven neural network simulator</td> <td>Python</td> <td>Research, education</td> <td> </td> </tr> <tr> <td><strong>NEURON</strong></td> <td>Detailed Modeling</td> <td>Biophysically detailed neuron models</td> <td>Python/C++</td> <td>Detailed biophysical models</td> <td> </td> </tr> <tr> <td><strong>STEPS</strong></td> <td>Spatial Modeling</td> <td>Spatial stochastic simulation</td> <td>Python/C++</td> <td>Subcellular processes</td> <td> </td> </tr> </tbody> </table> </details> <details><summary>Analysis &amp; Visualization Tools</summary> <table> <thead> <tr> <th>Tool</th> <th>Category</th> <th>Description</th> <th>Language</th> <th>Best For</th> <th>URL</th> </tr> </thead> <tbody> <tr> <td><strong>DeepLabCut</strong></td> <td>Behavioral Analysis</td> <td>Markerless pose estimation</td> <td>Python</td> <td>Animal behavior tracking</td> <td> </td> </tr> <tr> <td><strong>PyTorch</strong></td> <td>Deep Learning</td> <td>Research-focused ML framework</td> <td>Python</td> <td>NeuroAI model development</td> <td> </td> </tr> <tr> <td><strong>TensorFlow</strong></td> <td>Deep Learning</td> <td>Production-focused ML framework</td> <td>Python</td> <td>Deployment and large-scale apps</td> <td> </td> </tr> </tbody> </table> </details> <hr/> <p><em>This resource hub is community-maintained. Feel free to contribute through PRs or suggestions for additional resources, corrections, or organizational improvements.</em></p>]]></content><author><name></name></author><category term="artificial-intelligence"/><category term="comp-neursci"/><category term="math"/><summary type="html"><![CDATA[AI, Math and Neuroscience]]></summary></entry><entry xml:lang="en"><title type="html">Harvard CS197 AI Research Experiences</title><link href="https://sabertoaster.github.io/vi/blog/2025/harvard-cs197/" rel="alternate" type="text/html" title="Harvard CS197 AI Research Experiences"/><published>2025-07-01T12:00:00+00:00</published><updated>2025-07-01T12:00:00+00:00</updated><id>https://sabertoaster.github.io/blog/2025/harvard-cs197</id><content type="html" xml:base="https://sabertoaster.github.io/blog/2025/harvard-cs197/"><![CDATA[<p>Disclaimer: I didn’t own any of the contents and it all belongs to the rightful owner credited/ mentioned/ referenced at the end of the post.</p> <h2 id="brief-introduction">Brief introduction</h2> <p>This is a course ran by Harvard, instructed by Professor <a href="https://pranavrajpurkar.com/">Pranav Rajpurkar</a>.</p> <blockquote> <p>Dive into cutting-edge development tools like PyTorch, Lightning, and Hugging Face, and streamline your workflow with VSCode, Git, and Conda. You’ll learn how to harness the power of the cloud with AWS and Colab to train massive deep learning models with lightning-fast GPU acceleration. Plus, you’ll master best practices for managing a large number of experiments with Weights and Biases. And that’s just the beginning! This course will also teach you how to systematically read research papers, generate new ideas, and present them in slides or papers. You’ll even learn valuable project management and team communication techniques used by top AI researchers. Don’t miss out on this opportunity to level up your AI skills.</p> </blockquote> <hr/> <h2 id="chapter-1--2-introduction-to-ai-and-setting-up-environment">Chapter <a href="https://docs.google.com/document/u/0/d/1FHnGGGhTTarovEAVzSfELlNvxhXFJV4DkpuGgMKaEGw/edit">1</a> &amp; <a href="https://docs.google.com/document/u/0/d/1z5ELxpTw_U01jUB6-D6ILqHRPg6SSiLE7VFQryH3LPU/edit">2</a>: Introduction to AI and Setting up environment</h2> <p>Typical, intuitive guides to interact with AI and its research + development. Working environment requires source-code version control (Git), environment control (Conda) and editors (VSCode).</p> <hr/> <h2 id="chapter-3-reading-ai-research-papers"><a href="https://docs.google.com/document/d/1bPhwNdCCKkm1_adD0rx1YV6r2JG98qYmTxutT5gdAdQ/edit?tab=t.0">Chapter 3: Reading AI Research Papers</a></h2> <h3 id="ch3-objectives"><u>Objectives</u>:</h3> <ul> <li>Conduct a literature search to identify papers relevant to a topic of interest</li> <li>Read a machine learning research paper and summarize its contributions</li> </ul> <h3 id="ch3-content"><u>Chapter's content</u>:</h3> <details><summary>TLDR: Read wide for learning, read deep for improving. Take incremental approach.</summary> <blockquote> <p>I’m going to break down the process of reading AI research papers into two pieces: reading wide, and reading deep. <em><span style="color:red">When you start learning about a new topic, you typically get more out of reading wide</span></em>: this means navigating through literature reading small amounts of individual research papers. Our goal when reading wide is to build and improve our mental model of a research topic. <em><span style="color:red">Once you have identified key works that you want to understand well in the first step, you will want to read deep</span></em>: here, you are trying to read individual papers in depth. Both reading wide and deep are necessary and complimentary, especially when you’re getting started.</p> </blockquote> <h4 id="read-wide">Read wide:</h4> <p>Paperswithcode (AI/ML) | Google scholar | ACM Digital Lib &gt; Taking notes &gt; Check benchmark with recent submissions &gt; Check SOTA &gt; Check dataset (in any order) &gt; Read em and take notes. <br/> Results: Notes condensed with information, may take up to 2-3 hours doing this.</p> <blockquote> <p>At this point, I find myself particularly intrigued by the SOTA methods: Why are they achieving high performance? According to the review paper, it looks like “training strategies using pre-training” have been an advance. Maybe that’s worth keeping an eye out for!</p> </blockquote> <h4 id="read-deep">Read deep:</h4> <blockquote> <p>So I would like you to take an incremental approach here. Understand that, in your first pass, you will not understand more than 10% of the research paper. The paper may require us to read another more fundamental paper (which might require reading a third paper and so on; it could be turtles all the way down)! Then, in your second pass, you might understand 20% of the paper. Understanding 100% of a paper might require a significant leap, maybe because it’s poorly written, insufficiently detailed, or simply too technically/mathematically advanced. We thus want to aim to build up to understanding as much of the paper as possible – I’ll bet that 70-80% of the paper is a good target.</p> </blockquote> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog/2025/07/harvard-cs197-lec3-480.webp 480w,/assets/img/blog/2025/07/harvard-cs197-lec3-800.webp 800w,/assets/img/blog/2025/07/harvard-cs197-lec3-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/blog/2025/07/harvard-cs197-lec3.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Define your own highlight strategy, for example:</p> <ul> <li>The <span style="color:yellow">yellow highlights</span> are the problems/challenges</li> <li>The <span style="color:pink">pink highlights</span> are the solutions to the challenges</li> <li>The <span style="color:orange">orange highlights</span> are the main contributions of the work we’re reading.</li> </ul> <h3 id="ch3-tips"><u>Some useful tips</u>:</h3> <ul> <li> <p>Read deep: do a <a href="http://ccr.sigcomm.org/online/files/p83-keshavA.pdf">three-pass approach</a>. <br/><br/> First, take a quick scan through the title, put some brief thought into it. Read the abstract, introduction, section headings. <strong>Identify the research question, the thematics, the papers’ contribution.</strong> Look through the figures for visual details. Glance through <strong>discussion</strong> if exists. Read the conclusion and see if the research question have been solved (?) <br/><br/> Second, focus on the introduction content, preliminary. Grasp the underlying content in <strong>methodology</strong> section and the <strong>results</strong>. Take notes on key points. Skip math terms if too heavy. The goal is to understand the paper’s content without getting bogged down in details. <br/><br/> This pass is a thorough, line-by-line reading with the aim of understanding every detail and challenging the author’s assumptions and claims. This pass is particularly useful for papers that require a deep understanding or are central. <strong>Re-implement</strong> the paper’s work/ <strong>identify areas for improvement</strong>.</p> </li> <li> <p>Read wide: If <strong>doing a literature review/ search, just do the first pass</strong> then look for referenced sources, mentioned SOTA methods, prominent proposed dataset/ benchmark, …</p> </li> <li> <blockquote> <p>You would have thus created a list of concepts you need to learn about, and the relevant paper for each, if the paper specifies any.</p> </blockquote> </li> </ul> </details> <hr/> <h2 id="chapter-4-fine-tuning-a-language-model-using-hugging-face"><a href="https://docs.google.com/document/d/18mTeEk1zfJDz-oY48oB96ryZRuiAWRbCLOMYKap8eXk/edit?tab=t.0">Chapter 4: Fine-tuning a Language Model using Hugging Face</a></h2> <h3 id="ch4-objectives"><u>Objectives</u>:</h3> <ul> <li>Load up and process a natural language processing dataset using the datasets library.</li> <li>Tokenize a text sequence, and understand the steps used in tokenization.</li> <li>Construct a dataset and training step for causal language modeling.</li> </ul> <h3 id="ch4-content"><u>Chapter's content</u>:</h3> <details><summary>TLDR: HuggingFace’s Dataloader -&gt; Tokenize -&gt; Train/Test split -&gt; Train and Evaluate -&gt; Upload to model hub</summary> <h4 id="huggingface">HuggingFace</h4> <ul> <li>Community/ Data science center for building, training and deploying ML models based on open src software.</li> <li><a href="https://huggingface.co/docs/transformers/tasks/language_modeling">Guide 1: Causal language mdeoling</a> and <a href="https://github.com/huggingface/notebooks/blob/main/examples/language_modeling_from_scratch.ipynb">Guide 2: Code </a> on how to fine tune.</li> </ul> <h4 id="load-up-a-dataset">Load up a dataset</h4> <p>HF’s <code class="language-plaintext highlighter-rouge">Datasets library</code>’s 3 main feats:</p> <ul> <li>Load/ process data from CSV/JSON/text or python dict/pandas.DataFrame</li> <li>Access/ share datasets (through HF’s hub)</li> <li>Can be used with DL frameworks (pandas, numpy, pytorch/ tensorflow) (interoperable - new vocab hehe)</li> </ul> <p><a href="https://huggingface.co/datasets/rajpurkar/squad">SQuAD</a> (Stanford Question Answering Dataset) dataset:</p> <ul> <li>Reading comprehension</li> <li>Questions posed by crowdworkers on a set of Wikipedia articles</li> <li>Answer is a segment of text, span from corresponding reading passage; or unanswerable.</li> </ul> <h4 id="tokenize">Tokenize</h4> <p>A tokenization pipeline in huggingface comprises several <a href="https://huggingface.co/course/chapter6/8?fw=pt">steps</a>:</p> <ul> <li>(1) Normalization (any cleanup of the text that is deemed necessary, such as removing spaces or accents, Unicode normalization, etc.)</li> <li>(2) Pre-tokenization (splitting the input into words)</li> <li>(3) Running the input through the model (using the pre-tokenized words to produce a sequence of tokens)</li> <li>(4) Post-processing (adding the special tokens of the tokenizer, generating the attention mask and token type IDs).</li> </ul> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog/2025/07/harvard-cs197-lec4-pipeline-480.webp 480w,/assets/img/blog/2025/07/harvard-cs197-lec4-pipeline-800.webp 800w,/assets/img/blog/2025/07/harvard-cs197-lec4-pipeline-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/blog/2025/07/harvard-cs197-lec4-pipeline.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <blockquote> <p>The above steps show how we can go from text into tokens. There are multiple rules that govern the process that are specific to certain models. For tokenization, there are three main subword tokenization algorithms: BPE (used by GPT-2 and others), WordPiece (used for example by BERT), and Unigram (used by T5 and others); we won’t go into any of these, but if you’re curious, you can learn about them <a href="https://huggingface.co/course/chapter6/4?fw=pt#algorithm-overview">here</a>.</p> </blockquote> <h4 id="data-processing">Data Processing</h4> <blockquote> <p>For causal language modeling (CLM), one of the data preparation steps often used is to concatenate the different examples together, and then split them into chunks of equal size. This is so that we can have a common length across all examples without needing to pad.</p> </blockquote> <p>From <br/>[<code class="language-plaintext highlighter-rouge">"I went to the yard.&lt;|endoftext|&gt;"</code>,<code class="language-plaintext highlighter-rouge">"You came here a long time ago from the west coast.&lt;|endoftext|&gt;"</code>], <br/>we might change this to: <br/>[<code class="language-plaintext highlighter-rouge">"I went to the yard.&lt;|endoftext|&gt;You came here"</code>, <code class="language-plaintext highlighter-rouge">"a long time ago from the west coast.&lt;|endoftext|&gt;"</code>]</p> <h4 id="finetuning-and-setup-trainer">Finetuning and setup <a href="https://huggingface.co/docs/transformers/v4.21.3/en/main_classes/trainer#transformers.Trainer">Trainer</a></h4> <p>Code sample:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">transformers</span> <span class="kn">import</span> <span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">TrainingArguments</span><span class="p">,</span> <span class="n">Trainer</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span><span class="sh">"</span><span class="s">distilgpt2</span><span class="sh">"</span><span class="p">)</span>
<span class="n">training_args</span> <span class="o">=</span> <span class="nc">TrainingArguments</span><span class="p">(</span>
    <span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">model_checkpoint</span><span class="si">}</span><span class="s">-squad</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">eval_strategy</span><span class="o">=</span><span class="sh">"</span><span class="s">epoch</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">2e-5</span><span class="p">,</span>
    <span class="n">weight_decay</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
    <span class="n">push_to_hub</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="nc">Trainer</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
    <span class="n">args</span><span class="o">=</span><span class="n">training_args</span><span class="p">,</span>
    <span class="n">train_dataset</span><span class="o">=</span><span class="n">small_train_dataset</span><span class="p">,</span>
    <span class="n">eval_dataset</span><span class="o">=</span><span class="n">small_eval_dataset</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">trainer</span><span class="p">.</span><span class="nf">train</span><span class="p">()</span>
</code></pre></div></div> <h4 id="model-evaluation">Model Evaluation</h4> <blockquote> <p>Because we want our model to assign high probabilities to sentences that are real, and low probabilities to fake sentences, we seek a model that assigns the highest probability to the test set. The metric we use is <a href="##" title="Investigate this more">‘perplexity’</a>, which we can think of as the inverse probability of the test set normalized by the number of words in the test set. Therefore, a lower perplexity is better.</p> </blockquote> <h4 id="generation-with-our-fine-tuned-model">Generation with our fine-tuned model</h4> <p>Code sample:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">transformers</span> <span class="kn">import</span> <span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">AutoTokenizer</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">rajpurkar/</span><span class="si">{</span><span class="n">model_checkpoint</span><span class="si">}</span><span class="s">-squad</span><span class="sh">"</span><span class="p">)</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">rajpurkar/</span><span class="si">{</span><span class="n">model_checkpoint</span><span class="si">}</span><span class="s">-squad</span><span class="sh">"</span><span class="p">)</span>
<span class="n">start_text</span> <span class="o">=</span> <span class="p">(</span><span class="sh">"</span><span class="s">A speedrun is a playthrough of a video game, </span><span class="se">\
</span><span class="s">or section of a video game, with the goal of </span><span class="se">\
</span><span class="s">completing it as fast as possible. Speedruns </span><span class="se">\
</span><span class="s">often follow planned routes, which may incorporate sequence </span><span class="se">\
</span><span class="s">breaking, and might exploit glitches that allow sections to </span><span class="se">\
</span><span class="s">be skipped or completed more quickly than intended. </span><span class="sh">"</span><span class="p">)</span>

<span class="n">prompt</span> <span class="o">=</span> <span class="sh">"</span><span class="s">What is the</span><span class="sh">"</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="nf">tokenizer</span><span class="p">(</span>
     <span class="n">start_text</span> <span class="o">+</span> <span class="n">prompt</span><span class="p">,</span>
     <span class="n">add_special_tokens</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
     <span class="n">return_tensors</span><span class="o">=</span><span class="sh">"</span><span class="s">pt</span><span class="sh">"</span><span class="p">)[</span><span class="sh">"</span><span class="s">input_ids</span><span class="sh">"</span><span class="p">]</span>

<span class="n">prompt_length</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">.</span><span class="nf">decode</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">generate</span><span class="p">(</span>
     <span class="n">inputs</span><span class="p">,</span>
     <span class="n">max_length</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
     <span class="n">do_sample</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
     <span class="n">top_k</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
     <span class="n">top_p</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span>
     <span class="n">temperature</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
     <span class="n">num_return_sequences</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="n">generated</span> <span class="o">=</span> <span class="n">prompt</span> <span class="o">+</span> <span class="n">tokenizer</span><span class="p">.</span><span class="nf">decode</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="n">prompt_length</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:]</span>

<span class="nf">print</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">.</span><span class="nf">decode</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
</code></pre></div></div> <p>Results:</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog/2025/07/harvard-cs197-lec4-result-480.webp 480w,/assets/img/blog/2025/07/harvard-cs197-lec4-result-800.webp 800w,/assets/img/blog/2025/07/harvard-cs197-lec4-result-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/blog/2025/07/harvard-cs197-lec4-result.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </details> <hr/> <h2 id="chapter-5-fine-tuning-a-vision-transformer-using-lightning"><a href="https://docs.google.com/document/d/1VnNYGEmVgvl5p8w2xzypGySajaRv6qvzqw7E7LEwQKI/edit?tab=t.0">Chapter 5: Fine-tuning a Vision Transformer using Lightning</a></h2> <h3 id="ch5-objectives"><u>Objectives</u>:</h3> <details><summary>Learning outcomes: <ul> <li>Interact with code to explore data loading and tokenization of images for Vision Transformers.</li> <li>Parse code for PyTorch architecture and modules for building a Vision Transformer.</li> <li>Get acquainted with an example training workflow with PyTorch Lightning.</li> </ul></summary> <blockquote> <p>Reading code is often an effective way of learning. Today we will step through an image classification workflow with Vision transformers. We will parse code to process a computer vision dataset, tokenize inputs for vision transformers, and build a training workflow using the Lightning (PyTorch Lightning) framework. You might be used to learning about a new AI framework with simple tutorials first that build in complexity. However, in research settings, you’ll often be faced with using codebases that use unfamiliar frameworks. Our lecture today reflects this very setting, and is thus structured as a walkthrough where you will be exposed to code that uses Pytorch Lightning and then proceed to understand parts of it.</p> </blockquote> </details> <p>Example notebook:</p> <ul> <li><a href="https://pytorch-lightning.readthedocs.io/en/latest/notebooks/course_UvA-DL/11-vision-transformer.html">Tutorial</a></li> <li><a href="https://github.com/rajpurkar/cs197-lec5">Finetuning a Vision Transformer using Lightning</a></li> </ul> <h3 id="ch5-content"><u>Chapter's content</u>:</h3> <details><summary>TLDR: Data Loading</summary> <h4 id="lightning">Lightning</h4> <ul> <li>Lightning is a framework for PyTorch that provides a high-level interface for training models.</li> <li>It allows you to write less boilerplate code and focus on the model architecture and training logic</li> </ul> <details><summary><a href="https://lightning.ai/docs/pytorch/stable/levels/core_skills.html#basic-skills">Basic skills in Lightning:</a></summary> <ol> <li>Train a model</li> <li>Add validation and test</li> <li>Use pretrained models</li> <li>Enable script parameters</li> <li>Understand and visualize your model</li> <li>Predict with your model</li> </ol> </details> <h4 id="pipeline">Pipeline</h4> </details> <hr/> <h2 id="chapter-6--7-solidifying-pytorch-fundamentals"><a href="https://docs.google.com/document/d/1dA8KmOTZePMRl3MixxM6Fb0H8IJhIyn_g-LUXbRHeqU/edit?tab=t.0">Chapter 6 &amp; 7: Solidifying PyTorch Fundamentals</a></h2> <hr/> <h2 id="chapter-8--9-organizing-model-training-with-weights--biases-and-hydra"><a href="https://docs.google.com/document/d/1kZCrACh8wHFFAinscHpbaHqMBKeErjOgXMVqKSUZIMU/edit?tab=t.0">Chapter 8 &amp; 9: Organizing Model Training with Weights &amp; Biases and Hydra</a></h2> <hr/> <h2 id="chapter-10--11-a-framework-for-generating-research-ideas"><a href="https://docs.google.com/document/d/15pnUpD47S6mAM-g4fwQvc2klYIb-GKgWex1oOlmNjvg/edit?tab=t.0#heading=h.puuns7thj5bs">Chapter 10 &amp; 11: A Framework for Generating Research Ideas</a></h2> <p>Chapter’s featured papers:</p> <ul> <li><a href="https://www.nature.com/articles/s41551-022-00936-9">Expert-level detection of pathologies from unannotated chest X-ray images via self-supervised learning</a></li> <li><a href="https://arxiv.org/pdf/2103.00020.pdf">CLIP (Learning Transferable Visual Models From Natural Language Supervision)</a></li> </ul> <h3 id="ch10-objectives"><u>Objectives</u>:</h3> <ul> <li><strong>Identify gaps in a research paper</strong>, including in the research question, experimental setup, and findings.</li> <li><strong>Generate ideas to build on a research paper</strong>, thinking about the elements of the task of interest, evaluation strategy and the proposed method.</li> <li>Iterate on your ideas to improve their quality.</li> </ul> <h3 id="ch10-content"><u>Chapter's content</u>:</h3> <p>/** I’ll save this for my AIC task **/</p> <hr/> <h2 id="chapter-12--13-structuring-a-research-paper">Chapter 12 &amp; 13: Structuring a Research Paper</h2> <hr/> <h2 id="chapter-14--15-aws-ec2-for-deep-learning-setup-optimization-and-hands-on-training-with-chexzero">Chapter 14 &amp; 15: AWS EC2 for Deep Learning: Setup, Optimization, and Hands-on Training with CheXzero</h2> <hr/> <h2 id="chapter-16--17-fine-tuning-your-stable-diffusion-model">Chapter 16 &amp; 17: Fine-Tuning Your Stable Diffusion Model</h2> <hr/> <h2 id="chapter-18-tips-to-manage-your-time-and-efforts">Chapter 18: Tips to Manage Your Time and Efforts</h2> <hr/> <h2 id="chapter-19-making-progress-and-impact-in-ai-research">Chapter 19: Making Progress and Impact in AI Research</h2> <hr/> <h2 id="chapter-20-tips-for-creating-high-quality-slides">Chapter 20: Tips for Creating High-Quality Slides</h2> <hr/> <h2 id="chapter-21-statistical-testing-to-compare-model-performances">Chapter 21: Statistical Testing to Compare Model Performances</h2> <hr/> <h2 id="exercises">Exercises:</h2> <h3 id="assignments">Assignments:</h3> <p>Assignment 1: The Language of Code <br/> Assignment 2: First Dive in AI <br/> Assignment 3: Torched <br/> Assignment 4: Spark Joy <br/> Assignment 5: Ideation and Organization <br/> Assignment 6: Stable Diffusion and Research Operations</p> <hr/> <h3 id="course-project">Course Project:</h3> <p>[Redacted]</p> <hr/> <h2 id="references">References:</h2> <p><br/> <a href="https://www.cs197.seas.harvard.edu/">Course Homepage</a> <br/> <a href="https://docs.google.com/document/d/1uvAbEhbgS_M-uDMTzmOWRlYxqCkogKRXdbKYYT98ooc/edit?tab=t.0#heading=h.act903jwq03w">Docs Content</a></p>]]></content><author><name></name></author><summary type="html"><![CDATA[Notes and commentaries]]></summary></entry></feed>